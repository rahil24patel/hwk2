{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dcf158b-73bc-4d57-9c39-cb299087e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA_ROOT /scion/5261/econ470001/ma-data/ma\n",
      "LANDSCAPE_DIR /scion/5261/econ470001/ma-data/ma/landscape/Extracted Data\n",
      "FFSCOST_ROOT /scion/5261/econ470001/ma-data/ffs-costs\n",
      "CMSPAY_DIR exists True\n",
      "OUTPUT_DIR /home/rpat638/econ470/a0/work/hwk2/data/output\n",
      "Target years [2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "\n",
    "def pick_existing(paths: list[Path]) -> Path:\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"No candidate path exists\\n\" + \"\\n\".join(map(str, paths)))\n",
    "\n",
    "CANDIDATE_MA_ROOTS = [\n",
    "    Path(\"/scion/5261/econ470001/ma-data/ma\"),\n",
    "    Path(\"/econ470/a0/work/ma-data/ma\"),\n",
    "    Path.cwd().parent / \"ma-data\" / \"ma\",\n",
    "]\n",
    "\n",
    "MA_ROOT = pick_existing(CANDIDATE_MA_ROOTS)\n",
    "LANDSCAPE_DIR = pick_existing([MA_ROOT / \"landscape\" / \"Extracted Data\"])\n",
    "FFSCOST_ROOT  = pick_existing([MA_ROOT.parent / \"ffs-costs\"])\n",
    "CMSPAY_DIR    = MA_ROOT / \"cms-payment\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"data/output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"MA_ROOT\", MA_ROOT)\n",
    "print(\"LANDSCAPE_DIR\", LANDSCAPE_DIR)\n",
    "print(\"FFSCOST_ROOT\", FFSCOST_ROOT)\n",
    "print(\"CMSPAY_DIR exists\", CMSPAY_DIR.exists())\n",
    "print(\"OUTPUT_DIR\", OUTPUT_DIR.resolve())\n",
    "\n",
    "YEARS = list(range(2014, 2020))\n",
    "print(\"Target years\", YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719e1c7f-625a-456f-b19a-331935521e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_colname(s: str) -> str:\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "def parse_year_from_name(p: Path) -> int | None:\n",
    "    m = re.search(r\"(20\\d{2})\", p.name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def detect_header_row_csv(path: Path, nrows: int = 100) -> int:\n",
    "    preview = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        nrows=nrows,\n",
    "        dtype=str,\n",
    "        encoding_errors=\"replace\",\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",\n",
    "    ).fillna(\"\").astype(str)\n",
    "\n",
    "    keys = [\n",
    "        \"state\", \"county\", \"contract\", \"contract id\",\n",
    "        \"plan\", \"plan id\", \"pbp\",\n",
    "        \"organization\", \"bid\", \"benchmark\", \"premium\",\n",
    "        \"code\", \"enrollment\", \"reimbursement\", \"per capita\",\n",
    "    ]\n",
    "\n",
    "    best_i = 0\n",
    "    best_hits = -1\n",
    "    for i in range(preview.shape[0]):\n",
    "        row = \" \".join(preview.iloc[i].tolist()).lower()\n",
    "        hits = sum(1 for k in keys if k in row)\n",
    "        if hits > best_hits:\n",
    "            best_hits = hits\n",
    "            best_i = i\n",
    "    return best_i\n",
    "\n",
    "def read_csv_autoheader(path: Path) -> pd.DataFrame:\n",
    "    header_row = detect_header_row_csv(path)\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        skiprows=header_row,\n",
    "        header=0,\n",
    "        dtype=str,\n",
    "        encoding_errors=\"replace\",\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",\n",
    "    )\n",
    "    df.columns = [norm_colname(c) for c in df.columns]\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "def first_col(cols: list[str], needles: list[str]) -> str | None:\n",
    "    cols_l = [c.lower() for c in cols]\n",
    "    for n in needles:\n",
    "        for i, c in enumerate(cols_l):\n",
    "            if n in c:\n",
    "                return cols[i]\n",
    "    return None\n",
    "\n",
    "def to_num(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(\n",
    "        s.astype(str)\n",
    "         .str.replace(\",\", \"\", regex=False)\n",
    "         .str.replace(\"$\", \"\", regex=False)\n",
    "         .str.replace(\"%\", \"\", regex=False)\n",
    "         .str.strip(),\n",
    "        errors=\"coerce\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e379f7f-66ec-4df3-8709-f391e80ac4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 landscape files 4\n",
      "  2014LandscapeSource file MA_AtoM 05292014.csv\n",
      "  2014LandscapeSource file MA_NtoW 05292014.csv\n",
      "  508_AlabamatoMontana 05292014.csv\n",
      "  508_NebraskatoWyoming 05292014.csv\n",
      "2015 landscape files 4\n",
      "  2015LandscapeSource file MA_AtoM 11042014.csv\n",
      "  2015LandscapeSource file MA_NtoW 11042014.csv\n",
      "  508_AlabamatoMontana 03182015.csv\n",
      "  508_NebraskatoWyoming 03182015.csv\n",
      "2016 landscape files 6\n",
      "  2016LandscapeSource file MA_AtoM 04222016.csv\n",
      "  2016LandscapeSource file MA_NtoW 04222016.csv\n",
      "  508_AlabamatoMontana 04222016.csv\n",
      "  508_NebraskatoWyoming 04222016.csv\n",
      "2017 landscape files 4\n",
      "  2017LandscapeSource file MA_AtoM 10182016.csv\n",
      "  2017LandscapeSource file MA_NtoW 10182016.csv\n",
      "  508_AlabamatoMontana 09222017.csv\n",
      "  508_NebraskatoWyoming 09222017.csv\n",
      "2018 landscape files 4\n",
      "  2018LandscapeSource file MA_AtoM 10142017.csv\n",
      "  2018LandscapeSource file MA_NtoW 10142017.csv\n",
      "  508_AlabamatoMontana 10012018.csv\n",
      "  508_NebraskatoWyoming 10012018.csv\n",
      "2019 landscape files 4\n",
      "  2019LandscapeSource file MA_AtoM 10122018.csv\n",
      "  2019LandscapeSource file MA_NtoW 10122018.csv\n",
      "  508_AlabamatoMontana 09032019.csv\n",
      "  508_NebraskatoWyoming 09032019.csv\n"
     ]
    }
   ],
   "source": [
    "def landscape_files_for_year(root: Path, year: int) -> list[Path]:\n",
    "    files = sorted([p for p in root.rglob(\"*.csv\") if p.is_file()])\n",
    "    hits = []\n",
    "    for p in files:\n",
    "        y = parse_year_from_name(p)\n",
    "        if y != year:\n",
    "            continue\n",
    "        n = p.name.lower()\n",
    "        if \"sanction\" in n or \"importantnotes\" in n or \"partd\" in n or \"part_d\" in n or \"premium\" in n:\n",
    "            continue\n",
    "        hits.append(p)\n",
    "    return hits\n",
    "\n",
    "for y in YEARS:\n",
    "    lf = landscape_files_for_year(LANDSCAPE_DIR, y)\n",
    "    print(y, \"landscape files\", len(lf))\n",
    "    for p in lf[:4]:\n",
    "        print(\" \", p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3d39a8-a76d-45cb-94ff-202fc7f64df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2014 2014LandscapeSource file MA_AtoM 05292014.csv shape (15444, 17)\n",
      "loaded 2014 2014LandscapeSource file MA_NtoW 05292014.csv shape (19536, 17)\n",
      "loaded 2014 508_AlabamatoMontana 05292014.csv shape (15855, 29)\n",
      "loaded 2014 508_NebraskatoWyoming 05292014.csv shape (20301, 29)\n",
      "loaded 2015 2015LandscapeSource file MA_AtoM 11042014.csv shape (15881, 17)\n",
      "loaded 2015 2015LandscapeSource file MA_NtoW 11042014.csv shape (17695, 17)\n",
      "loaded 2015 508_AlabamatoMontana 03182015.csv shape (16662, 28)\n",
      "loaded 2015 508_NebraskatoWyoming 03182015.csv shape (5675, 28)\n",
      "loaded 2016 2016LandscapeSource file MA_AtoM 04222016.csv shape (16096, 18)\n",
      "loaded 2016 2016LandscapeSource file MA_NtoW 04222016.csv shape (18122, 18)\n",
      "loaded 2016 508_AlabamatoMontana 04222016.csv shape (17046, 28)\n",
      "loaded 2016 508_NebraskatoWyoming 04222016.csv shape (20396, 28)\n",
      "loaded 2016 508_AlabamatoMontana 10182016.csv shape (17653, 30)\n",
      "loaded 2016 508_NebraskatoWyoming 10182016.csv shape (20213, 28)\n",
      "loaded 2017 2017LandscapeSource file MA_AtoM 10182016.csv shape (16827, 18)\n",
      "loaded 2017 2017LandscapeSource file MA_NtoW 10182016.csv shape (17675, 18)\n",
      "loaded 2017 508_AlabamatoMontana 09222017.csv shape (19371, 29)\n",
      "loaded 2017 508_NebraskatoWyoming 09222017.csv shape (23055, 28)\n",
      "loaded 2018 2018LandscapeSource file MA_AtoM 10142017.csv shape (18289, 18)\n",
      "loaded 2018 2018LandscapeSource file MA_NtoW 10142017.csv shape (19820, 18)\n",
      "loaded 2018 508_AlabamatoMontana 10012018.csv shape (22229, 28)\n",
      "loaded 2018 508_NebraskatoWyoming 10012018.csv shape (27120, 28)\n",
      "loaded 2019 2019LandscapeSource file MA_AtoM 10122018.csv shape (20395, 18)\n",
      "loaded 2019 2019LandscapeSource file MA_NtoW 10122018.csv shape (23404, 18)\n",
      "loaded 2019 508_AlabamatoMontana 09032019.csv shape (27047, 30)\n",
      "loaded 2019 508_NebraskatoWyoming 09032019.csv shape (31002, 28)\n",
      "landscape_clean shape (502809, 10)\n",
      "years present [2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract_id</th>\n",
       "      <th>plan_id</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>organization_name</th>\n",
       "      <th>plan_name</th>\n",
       "      <th>bid</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>year</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H0104</td>\n",
       "      <td>10</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Blue Advantage (PPO)</td>\n",
       "      <td>Blue Advantage Premier (PPO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014LandscapeSource file MA_AtoM 05292014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H0104</td>\n",
       "      <td>11</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Blue Advantage (PPO)</td>\n",
       "      <td>Blue Advantage Complete (PPO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014LandscapeSource file MA_AtoM 05292014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H0150</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Cigna-HealthSpring</td>\n",
       "      <td>Cigna-HealthSpring Preferred (HMO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014LandscapeSource file MA_AtoM 05292014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H0150</td>\n",
       "      <td>12</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Cigna-HealthSpring</td>\n",
       "      <td>Cigna-HealthSpring Advantage (HMO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014LandscapeSource file MA_AtoM 05292014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H0151</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>UnitedHealthcare</td>\n",
       "      <td>AARP MedicareComplete Plan 1 (HMO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014LandscapeSource file MA_AtoM 05292014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  contract_id plan_id    state   county     organization_name                           plan_name  bid  benchmark  year                                    source_file\n",
       "0       H0104      10  Alabama  Autauga  Blue Advantage (PPO)        Blue Advantage Premier (PPO)  NaN        NaN  2014  2014LandscapeSource file MA_AtoM 05292014.csv\n",
       "1       H0104      11  Alabama  Autauga  Blue Advantage (PPO)       Blue Advantage Complete (PPO)  NaN        NaN  2014  2014LandscapeSource file MA_AtoM 05292014.csv\n",
       "2       H0150       1  Alabama  Autauga    Cigna-HealthSpring  Cigna-HealthSpring Preferred (HMO)  NaN        NaN  2014  2014LandscapeSource file MA_AtoM 05292014.csv\n",
       "3       H0150      12  Alabama  Autauga    Cigna-HealthSpring  Cigna-HealthSpring Advantage (HMO)  NaN        NaN  2014  2014LandscapeSource file MA_AtoM 05292014.csv\n",
       "4       H0151       1  Alabama  Autauga      UnitedHealthcare  AARP MedicareComplete Plan 1 (HMO)  NaN        NaN  2014  2014LandscapeSource file MA_AtoM 05292014.csv"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_landscape_clean(years: list[int]) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for y in years:\n",
    "        files = landscape_files_for_year(LANDSCAPE_DIR, y)\n",
    "        if not files:\n",
    "            print(\"No landscape CSVs found for\", y)\n",
    "            continue\n",
    "\n",
    "        chunks = []\n",
    "        for p in files:\n",
    "            df = read_csv_autoheader(p)\n",
    "            df[\"year\"] = y\n",
    "            df[\"source_file\"] = p.name\n",
    "            chunks.append(df)\n",
    "            print(\"loaded\", y, p.name, \"shape\", df.shape)\n",
    "\n",
    "        d = pd.concat(chunks, ignore_index=True)\n",
    "        cols = list(d.columns)\n",
    "\n",
    "        contract_col = first_col(cols, [\"contract_id\", \"contractid\", \"contract\"])\n",
    "        planid_col   = first_col(cols, [\"plan_id\", \"planid\", \"pbp\"])\n",
    "        if planid_col is None:\n",
    "            planid_col = first_col(cols, [\"plan_id_\"])\n",
    "        if planid_col is None:\n",
    "            planid_col = first_col(cols, [\"plan\"])\n",
    "        state_col  = first_col(cols, [\"state\"])\n",
    "        county_col = first_col(cols, [\"county\"])\n",
    "        bid_col    = first_col(cols, [\"bid\"])\n",
    "        bmk_col    = first_col(cols, [\"benchmark\"])\n",
    "        org_col    = first_col(cols, [\"organization\", \"org\"])\n",
    "        pname_col  = first_col(cols, [\"plan_name\", \"planname\"])\n",
    "\n",
    "        if contract_col is None or planid_col is None:\n",
    "            print(\"Year\", y, \"missing contract or plan columns\")\n",
    "            print(\"First 80 columns\", cols[:80])\n",
    "            continue\n",
    "\n",
    "        dd = pd.DataFrame()\n",
    "        dd[\"contract_id\"] = d[contract_col].astype(str).str.strip()\n",
    "        dd[\"plan_id\"]     = d[planid_col].astype(str).str.strip()\n",
    "        dd[\"state\"]       = d[state_col] if state_col is not None else np.nan\n",
    "        dd[\"county\"]      = d[county_col] if county_col is not None else np.nan\n",
    "        dd[\"organization_name\"] = d[org_col] if org_col is not None else np.nan\n",
    "        dd[\"plan_name\"]   = d[pname_col] if pname_col is not None else np.nan\n",
    "        dd[\"bid\"]         = to_num(d[bid_col]) if bid_col is not None else np.nan\n",
    "        dd[\"benchmark\"]   = to_num(d[bmk_col]) if bmk_col is not None else np.nan\n",
    "        dd[\"year\"]        = d[\"year\"]\n",
    "        dd[\"source_file\"] = d[\"source_file\"]\n",
    "\n",
    "        out.append(dd)\n",
    "\n",
    "    if not out:\n",
    "        raise RuntimeError(\"No landscape data loaded\")\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "landscape_clean = build_landscape_clean(YEARS)\n",
    "print(\"landscape_clean shape\", landscape_clean.shape)\n",
    "print(\"years present\", sorted(landscape_clean[\"year\"].unique().tolist()))\n",
    "landscape_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2d01a3e-177c-4a20-a8c4-62ae2054de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/output/landscape_clean_2014_2019.csv rows 502809\n"
     ]
    }
   ],
   "source": [
    "landscape_out = OUTPUT_DIR / \"landscape_clean_2014_2019.csv\"\n",
    "landscape_clean.to_csv(landscape_out, index=False)\n",
    "print(\"Wrote\", landscape_out, \"rows\", len(landscape_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc86911-425e-459e-af38-0f8b72e7094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openpyxl already available\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import openpyxl  # noqa\n",
    "    print(\"openpyxl already available\")\n",
    "except Exception as e:\n",
    "    print(\"openpyxl missing, installing with pip\")\n",
    "    !{sys.executable} -m pip install --user openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f7232e-286a-4e15-af34-415ea5f0bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASTER_PATH exists True\n",
      "Master years [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n"
     ]
    }
   ],
   "source": [
    "def build_fips_from_code(code_series: pd.Series) -> pd.Series:\n",
    "    code = code_series.astype(str).str.strip()\n",
    "    code = code.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    code = code.str.zfill(5)\n",
    "    return code\n",
    "\n",
    "def load_ffs_from_master(master_path: Path) -> pd.DataFrame:\n",
    "    df = read_csv_autoheader(master_path)\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    code_col = first_col(cols, [\"code\"])\n",
    "    year_col = first_col(cols, [\"year\"])\n",
    "    a_en_col = first_col(cols, [\"part_a_enrollment\"])\n",
    "    b_en_col = first_col(cols, [\"part_b_enrollment\"])\n",
    "    a_rb_col = first_col(cols, [\"part_a_total_reimbursement\"])\n",
    "    b_rb_col = first_col(cols, [\"part_b_total_reimbursement\"])\n",
    "\n",
    "    if code_col is None or year_col is None:\n",
    "        raise KeyError(\"FFS master missing code or year\")\n",
    "    if a_en_col is None or b_en_col is None or a_rb_col is None or b_rb_col is None:\n",
    "        raise KeyError(\"FFS master missing A or B enrollment or reimbursement columns\")\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"fips\"] = build_fips_from_code(tmp[code_col])\n",
    "    tmp[\"year\"] = pd.to_numeric(tmp[year_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    denom = (to_num(tmp[a_en_col]) + to_num(tmp[b_en_col])).replace(0, np.nan)\n",
    "    tmp[\"ffs_cost\"] = (to_num(tmp[a_rb_col]) + to_num(tmp[b_rb_col])) / denom\n",
    "\n",
    "    out = tmp[[\"fips\", \"year\", \"ffs_cost\"]].dropna(subset=[\"year\", \"ffs_cost\"]).copy()\n",
    "    out[\"year\"] = out[\"year\"].astype(int)\n",
    "    return out\n",
    "\n",
    "MASTER_PATH = FFSCOST_ROOT / \"CMS FFS Costs.csv\"\n",
    "print(\"MASTER_PATH exists\", MASTER_PATH.exists())\n",
    "\n",
    "ffs_master_cost = None\n",
    "if MASTER_PATH.exists():\n",
    "    ffs_master_cost = load_ffs_from_master(MASTER_PATH)\n",
    "    print(\"Master years\", sorted(ffs_master_cost[\"year\"].unique().tolist()))\n",
    "else:\n",
    "    print(\"No master found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574ee368-6555-430c-a774-f056432f7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_header_row_excel(path: Path, nrows: int = 80) -> int:\n",
    "    preview = pd.read_excel(path, header=None, nrows=nrows, engine=\"openpyxl\").fillna(\"\").astype(str)\n",
    "    keys = [\"code\", \"state\", \"county\", \"part a\", \"part b\", \"enrollment\", \"reimbursement\", \"per capita\"]\n",
    "    best_i = 0\n",
    "    best_hits = -1\n",
    "    for i in range(preview.shape[0]):\n",
    "        row = \" \".join(preview.iloc[i].tolist()).lower()\n",
    "        hits = sum(1 for k in keys if k in row)\n",
    "        if hits > best_hits:\n",
    "            best_hits = hits\n",
    "            best_i = i\n",
    "    return best_i\n",
    "\n",
    "def read_excel_autoheader(path: Path) -> pd.DataFrame:\n",
    "    header_row = detect_header_row_excel(path)\n",
    "    df = pd.read_excel(path, skiprows=header_row, header=0, engine=\"openpyxl\", dtype=str)\n",
    "    df.columns = [norm_colname(c) for c in df.columns]\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "def find_ffs_excel(ffscost_root: Path, year: int) -> Path | None:\n",
    "    extracted = ffscost_root / \"Extracted Data\"\n",
    "    yy = str(year)[-2:]\n",
    "    pats = [f\"*FFS{yy}*.xlsx\", f\"*ffs{yy}*.xlsx\", f\"*FFS{year}*.xlsx\", f\"*ffs{year}*.xlsx\"]\n",
    "    hits = []\n",
    "    for pat in pats:\n",
    "        hits.extend(list(extracted.rglob(pat)))\n",
    "    hits = [p for p in hits if p.is_file() and \"~$\" not in p.name]\n",
    "    if not hits:\n",
    "        return None\n",
    "    hits = sorted(hits, key=lambda p: (len(str(p)), str(p).lower()))\n",
    "    return hits[0]\n",
    "\n",
    "def load_ffs_from_excel_year(ffscost_root: Path, year: int) -> pd.DataFrame:\n",
    "    xlsx_path = find_ffs_excel(ffscost_root, year)\n",
    "    if xlsx_path is None:\n",
    "        raise FileNotFoundError(f\"Missing Excel for {year} under {ffscost_root}/Extracted Data\")\n",
    "\n",
    "    df = read_excel_autoheader(xlsx_path)\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    code_col = first_col(cols, [\"code\"])\n",
    "    a_en_col = first_col(cols, [\"part_a_enrollment\"])\n",
    "    b_en_col = first_col(cols, [\"part_b_enrollment\"])\n",
    "    a_rb_col = first_col(cols, [\"part_a_total_reimbursement\"])\n",
    "    b_rb_col = first_col(cols, [\"part_b_total_reimbursement\"])\n",
    "\n",
    "    if code_col is None:\n",
    "        raise KeyError(\"Excel missing code column\")\n",
    "    if a_en_col is None or b_en_col is None or a_rb_col is None or b_rb_col is None:\n",
    "        raise KeyError(\"Excel missing A or B enrollment or reimbursement columns\")\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"fips\"] = build_fips_from_code(tmp[code_col])\n",
    "    tmp[\"year\"] = year\n",
    "\n",
    "    denom = (to_num(tmp[a_en_col]) + to_num(tmp[b_en_col])).replace(0, np.nan)\n",
    "    tmp[\"ffs_cost\"] = (to_num(tmp[a_rb_col]) + to_num(tmp[b_rb_col])) / denom\n",
    "\n",
    "    out = tmp[[\"fips\", \"year\", \"ffs_cost\"]].dropna(subset=[\"ffs_cost\"]).copy()\n",
    "    print(\"Loaded\", year, \"from\", xlsx_path)\n",
    "    print(\"Rows\", len(out), \"ffs_cost nonmissing share\", out[\"ffs_cost\"].notna().mean())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646d2029-60fb-43dc-ba53-4efe339bc329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016 from /scion/5261/econ470001/ma-data/ffs-costs/Extracted Data/FFS16.xlsx\n",
      "Rows 3220 ffs_cost nonmissing share 1.0\n",
      "Loaded 2017 from /scion/5261/econ470001/ma-data/ffs-costs/Extracted Data/ffs2017/FFS17.xlsx\n",
      "Rows 3221 ffs_cost nonmissing share 1.0\n",
      "Loaded 2018 from /scion/5261/econ470001/ma-data/ffs-costs/Extracted Data/FFS2018/FFS18.xlsx\n",
      "Rows 3221 ffs_cost nonmissing share 1.0\n",
      "Loaded 2019 from /scion/5261/econ470001/ma-data/ffs-costs/Extracted Data/FFS2019/FFS19.xlsx\n",
      "Rows 3221 ffs_cost nonmissing share 1.0\n",
      "ffs_cost shape (19318, 3)\n",
      "years present [2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>year</th>\n",
       "      <th>ffs_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01000</td>\n",
       "      <td>2014</td>\n",
       "      <td>3740.899419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01010</td>\n",
       "      <td>2014</td>\n",
       "      <td>3654.810516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01020</td>\n",
       "      <td>2014</td>\n",
       "      <td>4060.929493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01030</td>\n",
       "      <td>2014</td>\n",
       "      <td>4338.152390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01040</td>\n",
       "      <td>2014</td>\n",
       "      <td>3776.224337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fips  year     ffs_cost\n",
       "0  01000  2014  3740.899419\n",
       "1  01010  2014  3654.810516\n",
       "2  01020  2014  4060.929493\n",
       "3  01030  2014  4338.152390\n",
       "4  01040  2014  3776.224337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = []\n",
    "\n",
    "if ffs_master_cost is not None:\n",
    "    pieces.append(ffs_master_cost[ffs_master_cost[\"year\"].isin(YEARS)].copy())\n",
    "\n",
    "for y in [2016, 2017, 2018, 2019]:\n",
    "    pieces.append(load_ffs_from_excel_year(FFSCOST_ROOT, y))\n",
    "\n",
    "ffs_cost = pd.concat(pieces, ignore_index=True)\n",
    "ffs_cost = ffs_cost.drop_duplicates(subset=[\"fips\", \"year\"]).copy()\n",
    "ffs_cost = ffs_cost[ffs_cost[\"year\"].isin(YEARS)].copy()\n",
    "\n",
    "print(\"ffs_cost shape\", ffs_cost.shape)\n",
    "print(\"years present\", sorted(ffs_cost[\"year\"].unique().tolist()))\n",
    "ffs_cost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f974db-cfca-4d3d-b540-1d2b241f7cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/output/ffs_cost_2014_2019.csv rows 19318\n"
     ]
    }
   ],
   "source": [
    "ffs_out = OUTPUT_DIR / \"ffs_cost_2014_2019.csv\"\n",
    "ffs_cost.to_csv(ffs_out, index=False)\n",
    "print(\"Wrote\", ffs_out, \"rows\", len(ffs_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d00580-3fd7-443d-be79-84b71d05cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffs18 rows 3221\n",
      "ffs_quartile\n",
      "1    806\n",
      "2    805\n",
      "3    805\n",
      "4    805\n",
      "Name: count, dtype: Int64\n",
      "Wrote data/output/ffs_cost_2018_with_quartiles.csv rows 3221\n"
     ]
    }
   ],
   "source": [
    "def quartile_codes(x: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "    cats = pd.qcut(x, 4, duplicates=\"drop\")\n",
    "    codes = cats.cat.codes.replace(-1, np.nan) + 1\n",
    "    return codes.astype(\"Int64\")\n",
    "\n",
    "ffs18 = ffs_cost[ffs_cost[\"year\"] == 2018].copy()\n",
    "print(\"ffs18 rows\", len(ffs18))\n",
    "\n",
    "ffs18[\"ffs_quartile\"] = quartile_codes(ffs18[\"ffs_cost\"])\n",
    "print(ffs18[\"ffs_quartile\"].value_counts(dropna=False).sort_index())\n",
    "\n",
    "ffs18_out = OUTPUT_DIR / \"ffs_cost_2018_with_quartiles.csv\"\n",
    "ffs18[[\"fips\", \"year\", \"ffs_cost\", \"ffs_quartile\"]].to_csv(ffs18_out, index=False)\n",
    "print(\"Wrote\", ffs18_out, \"rows\", len(ffs18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6943aa0-91c5-4561-a450-237d129f926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames you should have now\n",
      "['_', '_10', '_5', '__', 'ffs18', 'ffs_cost', 'ffs_master_cost', 'landscape_clean']\n",
      "Files in output\n",
      "['ffs_cost_2014_2019.csv', 'ffs_cost_2018_with_quartiles.csv', 'landscape_clean_2014_2019.csv']\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrames you should have now\")\n",
    "objs = {k: v for k, v in globals().items() if isinstance(v, pd.DataFrame)}\n",
    "print(sorted(objs.keys()))\n",
    "print(\"Files in output\")\n",
    "print(sorted([p.name for p in OUTPUT_DIR.glob(\"*.csv\")]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
